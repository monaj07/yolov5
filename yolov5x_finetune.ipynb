{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4I8FLVk4-31"
   },
   "outputs": [],
   "source": [
    "!pip install PyYAML==5.3.1\n",
    "!pip install git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joXLtvf85ORR"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/clothing.json', 'r') as f:\n",
    "    images = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GbrRoG_K7IPT",
    "outputId": "98639a77-aa92-463f-d26a-9aba7f749816"
   },
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKuIAcQ27J9f",
    "outputId": "12593f80-dccc-471b-8bc3-211932c824b1"
   },
   "outputs": [],
   "source": [
    "for img in images:\n",
    "    if len(img['annotation']) > 1:\n",
    "        print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNrsk5bw7nOA",
    "outputId": "fda9ce29-9b2f-4899-e130-8dd55c99858b"
   },
   "outputs": [],
   "source": [
    "classes = set()\n",
    "for img in images:\n",
    "    for ann in img['annotation']:\n",
    "        classes.add(ann['label'][0])\n",
    "classes = sorted(list(classes))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QN9ZF4xY8YsE",
    "outputId": "394c3eff-cc5c-45fa-be8b-11cd24a74f0f"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(images, test_size=0.15, \n",
    "                                         random_state=1)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, \n",
    "                                        random_state=1)\n",
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "mkLEvqON-Shc",
    "outputId": "0f215e9d-b1e9-4977-f2ba-339a5533b648"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from urllib import request\n",
    "\n",
    "img = Image.open(request.urlopen(train_data[0]['content']))\n",
    "img = img.convert('RGB')\n",
    "img.save('sample_img.jpeg', 'JPEG')\n",
    "\n",
    "img = np.array(img)\n",
    "plt.imshow(img); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "EXQMTT-3_IG1",
    "outputId": "480c6cc9-e0d9-49ba-824f-8dad516d3475"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def overlay_bbox(img, label, box_points):\n",
    "    H, W = img.shape[:-1]\n",
    "    p1, p2 = box_points\n",
    "    x1, y1 = p1['x'] * W, p1['y'] * H\n",
    "    x2, y2 = p2['x'] * W, p2['y'] * H\n",
    "\n",
    "    cv2.rectangle(img, \n",
    "                  (int(x1), int(y1)),\n",
    "                  (int(x2), int(y2)),\n",
    "                  color=(0, 255, 0),\n",
    "                  thickness=2)\n",
    "    \n",
    "    (label_width, label_height), _ = cv2.getTextSize(\n",
    "        label, \n",
    "        fontFace=cv2.FONT_HERSHEY_PLAIN,\n",
    "        fontScale=1.75, \n",
    "        thickness=2)\n",
    "\n",
    "    cv2.rectangle(img, \n",
    "                  (int(x1), int(y1)),\n",
    "                  (int(x1 + label_width), int(y1 + label_height)),\n",
    "                  color=(0, 255, 0),\n",
    "                  thickness=cv2.FILLED)\n",
    "    \n",
    "    cv2.putText(\n",
    "        img,\n",
    "        label,\n",
    "        org=(int(x1), int(y1 + label_height)),\n",
    "        fontFace=cv2.FONT_HERSHEY_PLAIN,\n",
    "        fontScale=1.75,\n",
    "        color=(255, 255, 255),\n",
    "        thickness=2\n",
    "    )\n",
    "\n",
    "    return img\n",
    "\n",
    "img_bbox = overlay_bbox(img, \n",
    "                        train_data[0]['annotation'][0]['label'][0], \n",
    "                        train_data[0]['annotation'][0]['points'])\n",
    "plt.imshow(img_bbox); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvRtvWV3ENCA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_dataset(dataset, classes, split, path='data'):\n",
    "    \"\"\"\n",
    "    YOLO v5 requires the dataset to be in the darknet format. \n",
    "    Here's an outline of what it looks like:\n",
    "\n",
    "    One txt with labels file per image\n",
    "    One row per object\n",
    "    Each row: class_index bbox_x_center bbox_y_center bbox_width bbox_height\n",
    "    Box coordinates must be normalized between 0 and 1\n",
    "    \"\"\"\n",
    "    image_path = os.path.join(path, 'images', split)\n",
    "    os.makedirs(image_path, exist_ok=True)\n",
    "    label_path = os.path.join(path, 'labels', split)\n",
    "    os.makedirs(label_path, exist_ok=True)\n",
    "\n",
    "    for idx, data in enumerate(dataset):\n",
    "        img = request.urlopen(data['content'])\n",
    "        img = Image.open(img).convert('RGB')\n",
    "        img.save(os.path.join(image_path, f'{idx:04d}.jpeg'), 'JPEG')\n",
    "\n",
    "        with open(os.path.join(label_path, f'{idx:04d}.txt'), 'w') as f:\n",
    "            for ann in data['annotation']:\n",
    "                label = ann['label'][0]\n",
    "                category_idx = classes.index(label)\n",
    "                points = ann['points']\n",
    "                p1, p2 = points\n",
    "                x1, y1 = p1['x'], p1['y']\n",
    "                x2, y2 = p2['x'], p2['y']\n",
    "                bbox_width = x2 - x1\n",
    "                bbox_height = y2 - y1\n",
    "                f.write(\n",
    "                  f\"{category_idx} {x1 + bbox_width / 2} {y1 + bbox_height / 2} {bbox_width} {bbox_height}\\n\"\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R8sD1EaYDG55"
   },
   "outputs": [],
   "source": [
    "create_dataset(train_data, classes, 'train')\n",
    "create_dataset(val_data, classes, 'val')\n",
    "create_dataset(test_data, classes, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "\n",
    "* img 320 - resize the images to 320x320 pixels (Larger is better, e.g. 640)\n",
    "* batch 4 - 4 images per batch\n",
    "* epochs 30 - train for 30 epochs\n",
    "* data ./data/clothing.yaml - path to dataset config\n",
    "* cfg ./models/yolov5x_9class.yaml - model config\n",
    "* weights yolov5x.pt - use pre-trained weights from the YOLOv5x model\n",
    "* name yolov5x_clothing - name of our model\n",
    "* cache - cache dataset images for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B73p0ss3K8uh",
    "outputId": "b5aca3bd-3f67-4bd2-a99e-2205056d4353"
   },
   "outputs": [],
   "source": [
    "!python train.py --img 320 --batch 4 --epochs 30 \\\n",
    "  --data data/clothing.yaml --cfg models/yolov5x_9class.yaml --weights yolov5x.pt \\\n",
    "  --name yolov5x_clothing --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "DBTeSCcKLw-6",
    "outputId": "56a5a7b4-e22e-4714-bab4-008ee5cc32fb"
   },
   "outputs": [],
   "source": [
    "from utils.plots import plot_results\n",
    "\n",
    "plot_results(save_dir='./runs/train/yolov5x_clothing/');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7HBo6WHPuN8",
    "outputId": "f1ea200a-cf35-4517-f34e-fefcaafbdd9a"
   },
   "outputs": [],
   "source": [
    "!python detect.py --weights runs/train/yolov5x_clothing/weights/best.pt \\\n",
    "  --img 320 --conf 0.4 --source data/images/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-eUKs6ISQbp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "def load_image(path, resize=True):\n",
    "    img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (128, 256), interpolation = cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "def show_grid(image_paths):\n",
    "    images = [load_image(img) for img in image_paths]\n",
    "    images = torch.as_tensor(images)\n",
    "    images = images.permute(0, 3, 1, 2)\n",
    "    grid_img = torchvision.utils.make_grid(images, nrow=11)\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    plt.imshow(grid_img.permute(1, 2, 0))\n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "HyNAJmG4S5il",
    "outputId": "f3a31307-1281-4af9-e754-4b0cd5261309"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "img_paths = list(glob(\"runs/detect/exp/*.jpeg\"))[:22]\n",
    "show_grid(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eA2zvSaeTPIv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "yolov5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
